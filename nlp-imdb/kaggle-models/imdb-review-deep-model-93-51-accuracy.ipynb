{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":["from importlib import reload\n","import sys\n","from imp import reload\n","import warnings\n","warnings.filterwarnings('ignore')\n","if sys.version[0] == '2':\n","    reload(sys)\n","    sys.setdefaultencoding(\"utf-8\")\n","import tensorflow as tf\n","# TF_FORCE_GPU_ALLOW_GROWTH=1\n","import tensorflow as tf\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","  try:\n","    for gpu in gpus:\n","      tf.config.experimental.set_memory_growth(gpu, True)\n","  except RuntimeError as e:\n","    print(e)\n","\n"],"execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":["import pandas as pd\n","\n","df1 = pd.read_csv('../../data/labeledTrainData.tsv', delimiter=\"\\t\")\n","df1 = df1.drop(['id'], axis=1)\n","df1.head()"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   sentiment                                             review\n","0          1  With all this stuff going down at the moment w...\n","1          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n","2          0  The film starts with a manager (Nicholas Bell)...\n","3          0  It must be assumed that those who praised this...\n","4          1  Superbly trashy and wondrously unpretentious 8..."],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>With all this stuff going down at the moment w...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>The film starts with a manager (Nicholas Bell)...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>It must be assumed that those who praised this...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Superbly trashy and wondrously unpretentious 8...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":2}]},{"metadata":{"trusted":true,"_uuid":"43cbec25f37de8995907c9ae65e9411fca06ee55"},"cell_type":"code","source":["df2 = pd.read_csv('../../data/imdb_master.csv',encoding=\"latin-1\")\n","df2.head()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0  type                                             review label  \\\n","0           0  test  Once again Mr. Costner has dragged out a movie...   neg   \n","1           1  test  This is an example of why the majority of acti...   neg   \n","2           2  test  First of all I hate those moronic rappers, who...   neg   \n","3           3  test  Not even the Beatles could write songs everyon...   neg   \n","4           4  test  Brass pictures (movies is not a fitting word f...   neg   \n","\n","          file  \n","0      0_2.txt  \n","1  10000_4.txt  \n","2  10001_1.txt  \n","3  10002_3.txt  \n","4  10003_3.txt  "],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>type</th>\n      <th>review</th>\n      <th>label</th>\n      <th>file</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>test</td>\n      <td>Once again Mr. Costner has dragged out a movie...</td>\n      <td>neg</td>\n      <td>0_2.txt</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>test</td>\n      <td>This is an example of why the majority of acti...</td>\n      <td>neg</td>\n      <td>10000_4.txt</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>test</td>\n      <td>First of all I hate those moronic rappers, who...</td>\n      <td>neg</td>\n      <td>10001_1.txt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>test</td>\n      <td>Not even the Beatles could write songs everyon...</td>\n      <td>neg</td>\n      <td>10002_3.txt</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>test</td>\n      <td>Brass pictures (movies is not a fitting word f...</td>\n      <td>neg</td>\n      <td>10003_3.txt</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":3}]},{"metadata":{"trusted":true,"_uuid":"d9424b01c0ff0c4e0722c5fb1cc73f130c4c0813"},"cell_type":"code","source":["df2 = df2.drop(['Unnamed: 0','type','file'],axis=1)\n","df2.columns = [\"review\",\"sentiment\"]\n","df2.head()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              review sentiment\n","0  Once again Mr. Costner has dragged out a movie...       neg\n","1  This is an example of why the majority of acti...       neg\n","2  First of all I hate those moronic rappers, who...       neg\n","3  Not even the Beatles could write songs everyon...       neg\n","4  Brass pictures (movies is not a fitting word f...       neg"],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Once again Mr. Costner has dragged out a movie...</td>\n      <td>neg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This is an example of why the majority of acti...</td>\n      <td>neg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>First of all I hate those moronic rappers, who...</td>\n      <td>neg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Not even the Beatles could write songs everyon...</td>\n      <td>neg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Brass pictures (movies is not a fitting word f...</td>\n      <td>neg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":4}]},{"metadata":{"trusted":true,"_uuid":"6be14c5fc77cec6e434e0fb258933d31567f6f2c"},"cell_type":"code","source":["df2 = df2[df2.sentiment != 'unsup']\n","df2['sentiment'] = df2['sentiment'].map({'pos': 1, 'neg': 0})\n","df2.head()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              review  sentiment\n","0  Once again Mr. Costner has dragged out a movie...          0\n","1  This is an example of why the majority of acti...          0\n","2  First of all I hate those moronic rappers, who...          0\n","3  Not even the Beatles could write songs everyon...          0\n","4  Brass pictures (movies is not a fitting word f...          0"],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Once again Mr. Costner has dragged out a movie...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This is an example of why the majority of acti...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>First of all I hate those moronic rappers, who...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Not even the Beatles could write songs everyon...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Brass pictures (movies is not a fitting word f...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":5}]},{"metadata":{"trusted":true,"_uuid":"1f502985bfb208f282d096cf4eda4df52ba628e3"},"cell_type":"code","source":["df = pd.concat([df1, df2]).reset_index(drop=True)\n","df.head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   sentiment                                             review\n","0          1  With all this stuff going down at the moment w...\n","1          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n","2          0  The film starts with a manager (Nicholas Bell)...\n","3          0  It must be assumed that those who praised this...\n","4          1  Superbly trashy and wondrously unpretentious 8..."],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>With all this stuff going down at the moment w...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>The film starts with a manager (Nicholas Bell)...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>It must be assumed that those who praised this...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Superbly trashy and wondrously unpretentious 8...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":6}]},{"metadata":{"trusted":true,"_uuid":"e08a2867d342084bde763daecb65f094273b06c7","tags":[]},"cell_type":"code","source":["import re\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","stop_words = set(stopwords.words(\"english\")) \n","lemmatizer = WordNetLemmatizer()\n","\n","\n","def clean_text(text):\n","    text = re.sub(r'[^\\w\\s]','',text, re.UNICODE)\n","    text = text.lower()\n","    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n","    text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n","    text = [word for word in text if not word in stop_words]\n","    text = \" \".join(text)\n","    return text\n","\n","df['Processed_Reviews'] = df.review.apply(lambda x: clean_text(x))"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /home/daniel/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /home/daniel/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"]}]},{"metadata":{"trusted":true,"_uuid":"28850b4961bc5ece382efbfe28b997884feaa804"},"cell_type":"code","source":["df.head()"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":"   sentiment                                             review  \\\n0          1  With all this stuff going down at the moment w...   \n1          1  \\The Classic War of the Worlds\\&quot; by Timothy Hi...   \n2          0  The film starts with a manager (Nicholas Bell)...   \n3          0  It must be assumed that those who praised this...   \n4          1  Superbly trashy and wondrously unpretentious 8...   \n\n                                   Processed_Reviews  \n0  stuff go moment mj ive start listen music watc...  \n1  classic war world timothy hines entertain film...  \n2  film start manager nicholas bell give welcome ...  \n3  must assume praise film greatest film opera ev...  \n4  superbly trashy wondrously unpretentious 80 ex...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>review</th>\n      <th>Processed_Reviews</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>With all this stuff going down at the moment w...</td>\n      <td>stuff go moment mj ive start listen music watc...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n      <td>classic war world timothy hines entertain film...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>The film starts with a manager (Nicholas Bell)...</td>\n      <td>film start manager nicholas bell give welcome ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>It must be assumed that those who praised this...</td>\n      <td>must assume praise film greatest film opera ev...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Superbly trashy and wondrously unpretentious 8...</td>\n      <td>superbly trashy wondrously unpretentious 80 ex...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":17}]},{"metadata":{"trusted":true,"_uuid":"010bdbd431234117fda785d37ff82bbadbcc1ab4"},"cell_type":"code","source":["df.Processed_Reviews.apply(lambda x: len(x.split(\" \"))).mean()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["128.51009333333334"]},"metadata":{},"execution_count":8}]},{"metadata":{"trusted":true,"_uuid":"2e2dc8a1cd71d8be15ce4103b7bfccddcbb2cb3b","tags":[]},"cell_type":"code","source":["from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.layers import Dense , Input , LSTM , Embedding, Dropout , Activation, GRU, Flatten\n","from keras.layers import Bidirectional, GlobalMaxPool1D\n","from keras.models import Model, Sequential\n","from keras.layers import Convolution1D\n","from keras import initializers, regularizers, constraints, optimizers, layers\n","\n","max_features = 6000\n","tokenizer = Tokenizer(num_words=max_features)\n","tokenizer.fit_on_texts(df['Processed_Reviews'])\n","list_tokenized_train = tokenizer.texts_to_sequences(df['Processed_Reviews'])\n","\n","maxlen = 130\n","X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n","y = df['sentiment']\n","\n","embed_size = 128\n","model = Sequential()\n","model.add(Embedding(max_features, embed_size))\n","model.add(Bidirectional(LSTM(32, return_sequences = True)))\n","model.add(GlobalMaxPool1D())\n","model.add(Dense(20, activation=\"relu\"))\n","model.add(Dropout(0.05))\n","model.add(Dense(1, activation=\"sigmoid\"))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","batch_size = 100\n","epochs = 3\n","model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.2)"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","600/600 [==============================] - 11s 18ms/step - loss: 0.3324 - accuracy: 0.8518 - val_loss: 0.2346 - val_accuracy: 0.9188\n","Epoch 2/3\n","600/600 [==============================] - 10s 17ms/step - loss: 0.2167 - accuracy: 0.9154 - val_loss: 0.1871 - val_accuracy: 0.9323\n","Epoch 3/3\n","600/600 [==============================] - 10s 17ms/step - loss: 0.1655 - accuracy: 0.9392 - val_loss: 0.1396 - val_accuracy: 0.9576\n"]},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fe17435e5d0>"]},"metadata":{},"execution_count":9}]},{"metadata":{"trusted":true,"_uuid":"bf093d54044461be3954e535f66636d45abe93da"},"cell_type":"code","source":["df_test=pd.read_csv(\"../../data/testData.tsv\",header=0, delimiter=\"\\t\", quoting=3)\n","df_test.head()\n","df_test[\"review\"]=df_test.review.apply(lambda x: clean_text(x))\n","df_test[\"sentiment\"] = df_test[\"id\"].map(lambda x: 1 if int(x.strip('\"').split(\"_\")[1]) >= 5 else 0)\n","y_test = df_test[\"sentiment\"]\n","list_sentences_test = df_test[\"review\"]\n","list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n","X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)\n","prediction = model.predict(X_te)\n","y_pred = (prediction > 0.5)\n","from sklearn.metrics import f1_score, confusion_matrix\n","print('F1-score: {0}'.format(f1_score(y_pred, y_test)))\n","print('Confusion matrix:')\n","confusion_matrix(y_pred, y_test)"],"execution_count":11,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '../input/word2vec-nlp-tutorial/testData.tsv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-2c67aa65b2cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/word2vec-nlp-tutorial/testData.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"review\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentiment\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentiment\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/word2vec-nlp-tutorial/testData.tsv'"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.9-final","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}